Name:Sushma Veluru

700#: 700765390

CRN: 23848






1. GAN Architecture

Adversarial Process

Generator (G): Learns to map noise  to data space, aiming to produce synthetic samples  that the discriminator cannot distinguish from real data.

Discriminator (D): Learns to classify inputs as real or fake, outputting  for real data , and  for generated samples.

Objectives

Discriminator maximizes:



Generator minimizes the above loss w.r.t. its parameters (or equivalently maximizes  for stronger gradients).

Architecture Diagram



2. Ethics and AI Harm

Selected Harm: Misinformation in generative AI

Application Example: Fake news articles generated by text models, spreading false claims about public figures.

Mitigation Strategies:

Content Filtering & Fact-Checking: Post-generation verification against trusted sources; flag or block inconsistencies.

Transparency & Labeling: Embed metadata or visible watermarks indicating AI-generated content.

3. Basic GAN Implementation

This script (src/gan.py) trains a simple GAN on the MNIST dataset.

Usage

python src/gan.py --epochs 100 --batch-size 128 --save-interval 50

Epoch 0, 50, 100 outputs are saved to src/plots/ as epoch_0.png, epoch_50.png, and epoch_100.png.

Loss curves for generator and discriminator are plotted and saved.

4. Data Poisoning Simulation

This script (src/data_poisoning.py) flips labels of reviews containing a target phrase (e.g., "UC Berkeley").

Usage

python src/data_poisoning.py --poison-fraction 0.1

Generates:

Accuracy plots before vs. after poisoning.

Confusion matrices saved in src/plots/.

Provides printed summary of performance drop and error analysis.

5. Legal and Ethical Implications of GenAI

Key Concerns

Memorization of Private Data: Risk of disclosing personal information (GDPR/CCPA violations).

Copyright Infringement: Generating large excerpts of copyrighted text without fair use clarity.

Position on Restrictions: Models should exclude non-public personal data and be filtered to avoid verbatim reproduction of copyrighted works, balancing innovation with legal compliance.

6. Bias & Fairness Tools

Metric: False Negative Rate Parity

Definition: Proportion of actual positives misclassified; parity ensures equal FNR across groups.
